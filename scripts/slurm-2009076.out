  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:03<06:28,  3.93s/it]  9%|▉         | 9/100 [00:06<01:00,  1.51it/s] 10%|█         | 10/100 [00:07<00:53,  1.69it/s] 15%|█▌        | 15/100 [00:07<00:26,  3.27it/s] 18%|█▊        | 18/100 [00:10<00:41,  1.95it/s] 20%|██        | 20/100 [00:10<00:33,  2.41it/s] 24%|██▍       | 24/100 [00:10<00:20,  3.78it/s] 27%|██▋       | 27/100 [00:13<00:35,  2.03it/s] 33%|███▎      | 33/100 [00:16<00:33,  2.01it/s] 35%|███▌      | 35/100 [00:16<00:28,  2.32it/s] 41%|████      | 41/100 [00:19<00:26,  2.22it/s] 43%|████▎     | 43/100 [00:20<00:22,  2.49it/s] 49%|████▉     | 49/100 [00:23<00:22,  2.25it/s] 56%|█████▌    | 56/100 [00:23<00:11,  3.72it/s] 58%|█████▊    | 58/100 [00:26<00:19,  2.17it/s] 65%|██████▌   | 65/100 [00:29<00:15,  2.19it/s] 72%|███████▏  | 72/100 [00:29<00:08,  3.43it/s] 75%|███████▌  | 75/100 [00:32<00:10,  2.32it/s] 80%|████████  | 80/100 [00:32<00:06,  3.21it/s] 82%|████████▏ | 82/100 [00:35<00:08,  2.10it/s] 84%|████████▍ | 84/100 [00:35<00:06,  2.48it/s] 88%|████████▊ | 88/100 [00:36<00:03,  3.30it/s] 90%|█████████ | 90/100 [00:38<00:04,  2.02it/s] 95%|█████████▌| 95/100 [00:39<00:01,  3.28it/s] 97%|█████████▋| 97/100 [00:42<00:01,  1.86it/s]100%|██████████| 100/100 [00:42<00:00,  2.37it/s]
run 0
  0%|          | 0/250 [00:00<?, ?it/s]/scratch/network/ls1546/.conda/main/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: Error detected in EMALossBackward. Traceback of forward call that caused the error:
  File "/scratch/network/ls1546/mine-pytorch/scripts/gabor_tryexcept.py", line 155, in <module>
    mi, loss_list = mine.optimize(torch.tensor(images_flat, dtype=torch.float32), torch.tensor(responses, dtype=torch.float32), epochs, batch_size, lam, run_name)
  File "/scratch/network/ls1546/mine-pytorch/mine/models/mine.py", line 134, in optimize
    loss = self.forward(x, y)
  File "/scratch/network/ls1546/mine-pytorch/mine/models/mine.py", line 97, in forward
    second_term, self.running_mean = ema_loss(
  File "/scratch/network/ls1546/mine-pytorch/mine/models/mine.py", line 61, in ema_loss
    t_log = EMALoss.apply(x, running_mean)
  File "/scratch/network/ls1546/.conda/main/lib/python3.10/site-packages/torch/autograd/function.py", line 539, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
 (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:114.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
epoch: 1, mu_mi: 0.000000:   0%|          | 0/250 [00:07<?, ?it/s]epoch: 1, mu_mi: 0.000000:   0%|          | 1/250 [00:07<29:21,  7.07s/it]epoch: 2, mu_mi: 0.000000:   0%|          | 1/250 [00:12<29:21,  7.07s/it]epoch: 2, mu_mi: 0.000000:   1%|          | 2/250 [00:12<26:00,  6.29s/it]epoch: 3, mu_mi: 0.000000:   1%|          | 2/250 [00:19<26:00,  6.29s/it]epoch: 3, mu_mi: 0.000000:   1%|          | 3/250 [00:19<26:48,  6.51s/it]epoch: 4, mu_mi: 0.000000:   1%|          | 3/250 [00:27<26:48,  6.51s/it]epoch: 4, mu_mi: 0.000000:   2%|▏         | 4/250 [00:27<28:38,  6.99s/it]epoch: 5, mu_mi: 0.000000:   2%|▏         | 4/250 [00:34<28:38,  6.99s/it]epoch: 5, mu_mi: 0.000000:   2%|▏         | 5/250 [00:34<28:08,  6.89s/it]epoch: 6, mu_mi: 0.000000:   2%|▏         | 5/250 [00:40<28:08,  6.89s/it]epoch: 6, mu_mi: 0.000000:   2%|▏         | 6/250 [00:40<26:46,  6.59s/it]epoch: 7, mu_mi: 0.000000:   2%|▏         | 6/250 [00:49<26:46,  6.59s/it]epoch: 7, mu_mi: 0.000000:   3%|▎         | 7/250 [00:49<30:50,  7.61s/it]epoch: 8, mu_mi: 0.000000:   3%|▎         | 7/250 [01:00<30:50,  7.61s/it]epoch: 8, mu_mi: 0.000000:   3%|▎         | 8/250 [01:00<35:16,  8.74s/it]epoch: 9, mu_mi: 0.000000:   3%|▎         | 8/250 [01:06<35:16,  8.74s/it]epoch: 9, mu_mi: 0.000000:   4%|▎         | 9/250 [01:06<31:09,  7.76s/it]epoch: 10, mu_mi: 0.000000:   4%|▎         | 9/250 [01:12<31:09,  7.76s/it]epoch: 10, mu_mi: 0.000000:   4%|▍         | 10/250 [01:12<29:19,  7.33s/it]epoch: 11, mu_mi: 0.000000:   4%|▍         | 10/250 [01:20<29:19,  7.33s/it]epoch: 11, mu_mi: 0.000000:   4%|▍         | 11/250 [01:20<29:53,  7.50s/it]epoch: 12, mu_mi: 0.000000:   4%|▍         | 11/250 [01:28<29:53,  7.50s/it]epoch: 12, mu_mi: 0.000000:   5%|▍         | 12/250 [01:28<29:29,  7.43s/it]epoch: 13, mu_mi: 0.000000:   5%|▍         | 12/250 [01:33<29:29,  7.43s/it]epoch: 13, mu_mi: 0.000000:   5%|▌         | 13/250 [01:33<26:56,  6.82s/it]epoch: 14, mu_mi: 0.000000:   5%|▌         | 13/250 [01:42<26:56,  6.82s/it]epoch: 14, mu_mi: 0.000000:   6%|▌         | 14/250 [01:42<29:26,  7.49s/it]epoch: 15, mu_mi: 0.000000:   6%|▌         | 14/250 [01:50<29:26,  7.49s/it]epoch: 15, mu_mi: 0.000000:   6%|▌         | 15/250 [01:50<30:13,  7.72s/it]epoch: 16, mu_mi: 0.000000:   6%|▌         | 15/250 [01:55<30:13,  7.72s/it]epoch: 16, mu_mi: 0.000000:   6%|▋         | 16/250 [01:55<27:07,  6.95s/it]epoch: 17, mu_mi: 0.000000:   6%|▋         | 16/250 [02:03<27:07,  6.95s/it]epoch: 17, mu_mi: 0.000000:   7%|▋         | 17/250 [02:03<27:37,  7.11s/it]epoch: 18, mu_mi: 0.000000:   7%|▋         | 17/250 [02:10<27:37,  7.11s/it]epoch: 18, mu_mi: 0.000000:   7%|▋         | 18/250 [02:10<27:40,  7.16s/it]epoch: 19, mu_mi: 0.000000:   7%|▋         | 18/250 [02:19<27:40,  7.16s/it]epoch: 19, mu_mi: 0.000000:   8%|▊         | 19/250 [02:19<29:15,  7.60s/it]epoch: 20, mu_mi: 0.000000:   8%|▊         | 19/250 [02:28<29:15,  7.60s/it]epoch: 20, mu_mi: 0.000000:   8%|▊         | 20/250 [02:28<31:07,  8.12s/it]epoch: 21, mu_mi: 0.000000:   8%|▊         | 20/250 [02:35<31:07,  8.12s/it]epoch: 21, mu_mi: 0.000000:   8%|▊         | 21/250 [02:35<30:07,  7.89s/it]epoch: 22, mu_mi: 0.000000:   8%|▊         | 21/250 [02:42<30:07,  7.89s/it]epoch: 22, mu_mi: 0.000000:   9%|▉         | 22/250 [02:42<28:31,  7.51s/it]epoch: 23, mu_mi: 0.000000:   9%|▉         | 22/250 [02:47<28:31,  7.51s/it]epoch: 23, mu_mi: 0.000000:   9%|▉         | 23/250 [02:47<25:53,  6.84s/it]epoch: 24, mu_mi: 0.000000:   9%|▉         | 23/250 [02:55<25:53,  6.84s/it]epoch: 24, mu_mi: 0.000000:  10%|▉         | 24/250 [02:55<26:51,  7.13s/it]epoch: 25, mu_mi: 0.000000:  10%|▉         | 24/250 [03:04<26:51,  7.13s/it]epoch: 25, mu_mi: 0.000000:  10%|█         | 25/250 [03:04<28:07,  7.50s/it]epoch: 26, mu_mi: 0.000000:  10%|█         | 25/250 [03:10<28:07,  7.50s/it]epoch: 26, mu_mi: 0.000000:  10%|█         | 26/250 [03:10<27:12,  7.29s/it]epoch: 27, mu_mi: 0.000000:  10%|█         | 26/250 [03:15<27:12,  7.29s/it]epoch: 27, mu_mi: 0.000000:  11%|█         | 27/250 [03:15<24:40,  6.64s/it]epoch: 28, mu_mi: 0.000000:  11%|█         | 27/250 [03:22<24:40,  6.64s/it]epoch: 28, mu_mi: 0.000000:  11%|█         | 28/250 [03:22<24:37,  6.65s/it]epoch: 29, mu_mi: 0.000000:  11%|█         | 28/250 [03:29<24:37,  6.65s/it]epoch: 29, mu_mi: 0.000000:  12%|█▏        | 29/250 [03:29<25:03,  6.80s/it]epoch: 30, mu_mi: 0.000000:  12%|█▏        | 29/250 [03:37<25:03,  6.80s/it]epoch: 30, mu_mi: 0.000000:  12%|█▏        | 30/250 [03:37<26:17,  7.17s/it]epoch: 31, mu_mi: 0.000000:  12%|█▏        | 30/250 [03:45<26:17,  7.17s/it]epoch: 31, mu_mi: 0.000000:  12%|█▏        | 31/250 [03:45<26:39,  7.30s/it]epoch: 32, mu_mi: 0.000000:  12%|█▏        | 31/250 [03:51<26:39,  7.30s/it]epoch: 32, mu_mi: 0.000000:  13%|█▎        | 32/250 [03:51<24:57,  6.87s/it]epoch: 33, mu_mi: 0.000000:  13%|█▎        | 32/250 [03:59<24:57,  6.87s/it]epoch: 33, mu_mi: 0.000000:  13%|█▎        | 33/250 [03:59<26:46,  7.40s/it]epoch: 34, mu_mi: 0.000000:  13%|█▎        | 33/250 [04:08<26:46,  7.40s/it]epoch: 34, mu_mi: 0.000000:  14%|█▎        | 34/250 [04:08<27:59,  7.78s/it]epoch: 35, mu_mi: 0.000000:  14%|█▎        | 34/250 [04:15<27:59,  7.78s/it]epoch: 35, mu_mi: 0.000000:  14%|█▍        | 35/250 [04:15<27:08,  7.57s/it]epoch: 36, mu_mi: 0.000000:  14%|█▍        | 35/250 [04:25<27:08,  7.57s/it]epoch: 36, mu_mi: 0.000000:  14%|█▍        | 36/250 [04:25<28:58,  8.12s/it]epoch: 37, mu_mi: 0.000000:  14%|█▍        | 36/250 [04:34<28:58,  8.12s/it]epoch: 37, mu_mi: 0.000000:  15%|█▍        | 37/250 [04:34<29:45,  8.38s/it]epoch: 38, mu_mi: 0.000000:  15%|█▍        | 37/250 [04:42<29:45,  8.38s/it]epoch: 38, mu_mi: 0.000000:  15%|█▌        | 38/250 [04:42<29:50,  8.44s/it]epoch: 39, mu_mi: 0.000000:  15%|█▌        | 38/250 [04:51<29:50,  8.44s/it]epoch: 39, mu_mi: 0.000000:  16%|█▌        | 39/250 [04:51<30:12,  8.59s/it]epoch: 40, mu_mi: 0.000000:  16%|█▌        | 39/250 [05:01<30:12,  8.59s/it]epoch: 40, mu_mi: 0.000000:  16%|█▌        | 40/250 [05:01<31:15,  8.93s/it]epoch: 41, mu_mi: 0.000000:  16%|█▌        | 40/250 [05:10<31:15,  8.93s/it]epoch: 41, mu_mi: 0.000000:  16%|█▋        | 41/250 [05:10<30:50,  8.86s/it]epoch: 42, mu_mi: 0.000000:  16%|█▋        | 41/250 [05:20<30:50,  8.86s/it]epoch: 42, mu_mi: 0.000000:  17%|█▋        | 42/250 [05:20<32:13,  9.30s/it]epoch: 43, mu_mi: 0.000000:  17%|█▋        | 42/250 [05:27<32:13,  9.30s/it]epoch: 43, mu_mi: 0.000000:  17%|█▋        | 43/250 [05:27<29:41,  8.61s/it]epoch: 44, mu_mi: 0.000000:  17%|█▋        | 43/250 [05:37<29:41,  8.61s/it]epoch: 44, mu_mi: 0.000000:  18%|█▊        | 44/250 [05:37<30:47,  8.97s/it]epoch: 45, mu_mi: 0.000000:  18%|█▊        | 44/250 [05:45<30:47,  8.97s/it]epoch: 45, mu_mi: 0.000000:  18%|█▊        | 45/250 [05:45<30:13,  8.85s/it]epoch: 46, mu_mi: 0.000000:  18%|█▊        | 45/250 [05:54<30:13,  8.85s/it]epoch: 46, mu_mi: 0.000000:  18%|█▊        | 46/250 [05:54<29:34,  8.70s/it]epoch: 47, mu_mi: 0.000000:  18%|█▊        | 46/250 [06:02<29:34,  8.70s/it]epoch: 47, mu_mi: 0.000000:  19%|█▉        | 47/250 [06:02<29:16,  8.65s/it]epoch: 48, mu_mi: 0.000000:  19%|█▉        | 47/250 [06:12<29:16,  8.65s/it]epoch: 48, mu_mi: 0.000000:  19%|█▉        | 48/250 [06:12<29:52,  8.87s/it]epoch: 48, mu_mi: 0.000000:  19%|█▉        | 48/250 [06:15<26:20,  7.82s/it]
Traceback (most recent call last):
  File "/scratch/network/ls1546/mine-pytorch/mine/models/mine.py", line 134, in optimize
    loss = self.forward(x, y)
  File "/scratch/network/ls1546/mine-pytorch/mine/models/mine.py", line 94, in forward
    t_marg = self.T(x, z_marg)
  File "/scratch/network/ls1546/.conda/main/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/network/ls1546/.conda/main/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/network/ls1546/mine-pytorch/scripts/gabor_tryexcept.py", line 144, in forward
    h = F.relu(self.fc2(h))
  File "/scratch/network/ls1546/.conda/main/lib/python3.10/site-packages/torch/nn/functional.py", line 1471, in relu
    result = torch.relu(input)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 79.33 GiB of which 1.69 MiB is free. Including non-PyTorch memory, this process has 79.31 GiB memory in use. Of the allocated memory 72.96 GiB is allocated by PyTorch, and 5.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/scratch/network/ls1546/mine-pytorch/scripts/gabor_tryexcept.py", line 155, in <module>
    mi, loss_list = mine.optimize(torch.tensor(images_flat, dtype=torch.float32), torch.tensor(responses, dtype=torch.float32), epochs, batch_size, lam, run_name)
  File "/scratch/network/ls1546/mine-pytorch/mine/models/mine.py", line 142, in optimize
    np.save(f"{datadir}{name}_batchx{batch_num}.npy", x.detach().cpu().numpy())
  File "/scratch/network/ls1546/.conda/main/lib/python3.10/site-packages/numpy/lib/npyio.py", line 544, in save
    with file_ctx as fid:
OSError: [Errno 122] Disk quota exceeded
